\documentclass[a0]{a0poster}
% You might find the 'draft' option to a0 poster useful if you have
% lots of graphics, because they can take some time to process and
% display. (\documentclass[a0,draft]{a0poster})
\input defs
\pagestyle{empty}
\setcounter{secnumdepth}{0}
\renewcommand{\familydefault}{\sfdefault}
\newcommand{\QED}{~~\rule[-1pt]{8pt}{8pt}}\def\qed{\QED}

\renewcommand{\reals}{{\mbox{\bf R}}}

% The textpos package is necessary to position textblocks at arbitary 
% places on the page.
\usepackage[absolute]{textpos}

\usepackage{fleqn,psfrag,wrapfig,tikz}

\usepackage[papersize={38in,28in}]{geometry}

% Graphics to include graphics. Times is nice on posters, but you
% might want to switch it off and go for CMR fonts.
\usepackage{graphics}

% we are running pdflatex, so convert .eps files to .pdf
%\usepackage[pdftex]{graphicx}
%\usepackage{epstopdf}

% These colors are tried and tested for titles and headers. Don't
% over use color!
\usepackage{color}
\definecolor{Red}{rgb}{0.9,0.0,0.1}

\definecolor{bluegray}{rgb}{0.15,0.20,0.40}
\definecolor{bluegraylight}{rgb}{0.35,0.40,0.60}
\definecolor{gray}{rgb}{0.3,0.3,0.3}
\definecolor{lightgray}{rgb}{0.7,0.7,0.7}
\definecolor{darkblue}{rgb}{0.2,0.2,1.0}
\definecolor{darkgreen}{rgb}{0.0,0.5,0.3}

\renewcommand{\labelitemi}{\textcolor{bluegray}\textbullet}
\renewcommand{\labelitemii}{\textcolor{bluegray}{--}}

\setlength{\labelsep}{0.5em}


% see documentation for a0poster class for the size options here
\let\Textsize\normalsize
%\def\Head#1{\noindent\hbox to \hsize{\hfil{\LARGE\color{bluegray} #1}}\bigskip}
\def\Head#1{\noindent{\LARGE\color{bluegray} #1}\bigskip}
\def\LHead#1{\noindent{\LARGE\color{bluegray} #1}\bigskip}
\def\Subhead#1{\noindent{\large\color{bluegray} #1}\bigskip}
\def\Title#1{\noindent{\VeryHuge\color{Red} #1}}


% Set up the grid
%
% Note that [40mm,40mm] is the margin round the edge of the page --
% it is _not_ the grid size. That is always defined as 
% PAGE_WIDTH/HGRID and PAGE_HEIGHT/VGRID. In this case we use
% 23 x 12. This gives us three columns of width 7 boxes, with a gap of
% width 1 in between them. 12 vertical boxes is a good number to work
% with.
%
% Note however that texblocks can be positioned fractionally as well,
% so really any convenient grid size can be used.
%
\TPGrid[40mm,40mm]{23}{12}      % 3 cols of width 7, plus 2 gaps width 1

\parindent=0pt
\parskip=0.2\baselineskip

\begin{document}

% Understanding textblocks is the key to being able to do a poster in
% LaTeX. In
%
%    \begin{textblock}{wid}(x,y)
%    ...
%    \end{textblock}
%
% the first argument gives the block width in units of the grid
% cells specified above in \TPGrid; the second gives the (x,y)
% position on the grid, with the y axis pointing down.

% You will have to do a lot of previewing to get everything in the 
% right place.

% This gives good title positioning for a portrait poster.
% Watch out for hyphenation in titles - LaTeX will do it
% but it looks awful.
\begin{textblock}{23}(0,0)
\Title{Detecting Humor in Yelp Reviews}
\end{textblock}

\begin{textblock}{23}(0,0.6)
{
\LARGE
Luke de Oliveira, Alfredo L\'{a}inez
}\\\\
{
\Large
\color{bluegray}
\emph{Institute for Computational and Mathematical Engineering (ICME)}
}
% {
% \Large
% \color{bluegray}
% \emph{CS224D}
% }
\end{textblock}


% Uni logo in the top right corner. A&A in the bottom left. Gives a
% good visual balance, but you may want to change this depending upon
% the graphics that are in your poster.
%\begin{textblock}{2}(0,10)
%Your logo here
%%\includegraphics{/usr/local/share/images/AandA.epsf}
%\end{textblock}

%\begin{textblock}{2}(21.2,0)
%Another logo here
%%\resizebox{2\TPHorizModule}{!}{\includegraphics{/usr/local/share/images/GUVIu/GUVIu.eps}}
%\end{textblock}


\begin{textblock}{7.0}(0,1.5)

\hrule\medskip
\Head{Introduction}\\
%Yelp's utility as an service relies on being able to provide an accurate, crowd-sourced opinion of a place of business. However, how can we determine which reviews provide valuable insight into a business? In addition, does humor play a role on the user-voted utility and are they related? We intend to predict community-determined vote distributions in Yelp reviews. 
Yelp's utility as a service relies on being able to provide an accurate, crowd-sourced opinion of a place of business. Business reviews, which play a central role in this service, can be voted by other users (``funny'', ``useful'', and ``cool''), so that the most interesting reviews can stand out. In this project we zero in on what makes a review useful or funny. For that, we will try to predict the number of funny votes that a review receives. We intend thus to utilize deep models to capture higher structures of humor in text.

\medskip
\hrule\medskip
\Head{Our Data}\\
We used the Yelp Dataset Challenge dataset, which consists of 1.6M reviews and 500K tips by 366K users for 61K businesses. Each review consists of one or more sentences commenting on the business at hand, along with vote-count given by users to the review -- particularly, ``funny'', ``useful'', and ``cool''.

\medskip
\hrule\medskip
\Head{Evaluation of Predictions}\\
As with any count based prediction problem, we are more concerned with the jump from 0 to 1 votes than the jump from 10 votes to 11. In accordance with this diminishing marginal utility, we use the metric outlined in Yelp's Kaggle competition, called Root Mean Squared Logarithmic Error (RMSLE). It is defined as

\begin{equation}
\mathsf{RMSLE}(\hat{y}, y) = \sqrt{\frac{1}{n}\sum_{i=1}^{n} (\log(1 + \hat{y_i}) - \log(1 + y_i))^2}.
\end{equation}

This allows us to focus on detecting the presence of humor rather that worrying about distinguishing between marginal humor.

%\medskip
%\hrule\medskip
%\Head{Work in Humor Detection}\\

%There is a distinct lack of research in the area of humor detection. Since humor in text often comes from sarcasm which is a difficult trait to pick up, we expect humor to be quite difficult to pick up. However, we intend to get some insights in what constitutes a ``funny'' review, such as trying to visualize activations on certain words or linguistic constructions, and then try to characterize the features of humor for the Yelp community.

\medskip
\hrule\medskip
\Head{Deep Learning approaches}\\
In order to use Deep Learning, we need to settle what deep models will be convenient for our task. We set out from the use of word vectors as our input. However, our dataset consists of full texts with a single number of votes each. Contrary to other fine-grained deep models, where labels can be found at a sentence or even word level, we only have results for full portions of text, so models such as tree-RNNs seem futile.

A first idea is similar to that of paragraph vectors. We can simply compute the average of all the word vectors in a review and apply it to deep feedforward networks. However, we are also interested in determining whether we can find humor in more complex patterns of text. For that, we aim at Convolutional Neural Networks, which provide different levels of trade-off between global and local structure, something that may be useful in learning higher order structure of humor. We also look at LSTM and GRU Recurrent Neural Networks, with the hope that memory layers will be able to capture humor sequential structures.
\end{textblock}

\begin{textblock}{7.0}(8,1.5)
\hrule\medskip
\Head{Baselines}\\
Since we are using a non-standard metric for our prediction, we take great care to understand the range of our metric. We define the \emph{all-zero} error to be the RMSLE when we predict all zeros for our $Y$ (which would be the best idea without prior information since most reviews don't get any funny votes). In order to develop a baseline for deep methods, we use two different feature representations with three ``shallow'' methods, spanning the range of what can be feasibly done without deep learning. We use basic Bag-of-Words with TF-IDF and Paragraph Vectors as feature representations. On top of each of these feature spaces, we use the following ``shallow'', classic ML algorithms.

\begin{itemize}
    \item Stochastic Gradient Descent for linear models (SGD)
    \item Support Vector Regression
    \item Gradient Boosting Machine (GBM)
\end{itemize}

Since we do not expect these models to carry much weight, we use them as a baseline. We obtained the following (tuned) results:

\begin{table}[h]
\centering
\vspace{2ex}
\begin{tabular}{l l l}
% \toprule
\textbf{Method} & \textbf{Test Error} & \textbf{All-zero-error}\tabularnewline
\hline
%\midrule
SVM Regression & 0.5071 & 0.5193\tabularnewline
\hline
SGD Linear Model & 0.4809 & 0.5142\tabularnewline
\hline
%\bottomrule
\end{tabular}
\caption{RMSLE of classical methods built on top of classical Bag-of-Words}
\end{table}

\begin{table}[h]
\centering
\vspace{2ex}
\begin{tabular}{l l l}
% \toprule
\textbf{Method} & \textbf{Test Error} & \textbf{All-zero-error}\tabularnewline
\hline
%\midrule
SVM Regression & 0.4927 & 0.5266\tabularnewline
\hline
GBM & 0.4868 & 0.5276\tabularnewline
\hline
%\bottomrule
\end{tabular}
\caption{RMSLE of classical methods built on top of paragraph vectors}
\end{table}

\medskip
\hrule\medskip
\Head{Deep Feedforward Results}\\
First, we illustrate results with building deep networks on top of mean-word-vector representations of phrases. We tune two different architectures: a two-layer maxout network with dropout (A), and a 4 layer deep rectifier network with dropout (B). After tuning and optimizing performance, we chose the a maxout network with structure [wordvector $\rightarrow$ Maxout(100, 100) $\rightarrow$ Maxout(100, 50) $\rightarrow$ ReLU(50, 1)] and 5 knots for the piecewise fit in each maxout layer. In addition, dropout of [0.4, 0.2] was used between layers. For the deep rectifier network, we had an architecture of [wordvector $\rightarrow$ ReLU(100, 150) $\rightarrow$ ReLU(150, 75) $\rightarrow$ ReLU(75, 10) $\rightarrow$ ReLU(10, 1)], with dropout probabilities of [0.5, 0.2, 0.1] between each fully connected layer. The networks were trained with batches of size 50 and Adagrad for optimization against the MSE cost. To optimize our actual objective, we take $\log(1 + y)$ to be our transformed targets.
\begin{table}[h]
\centering
\vspace{2ex}
\begin{tabular}{l l l l l}
% \toprule
\textbf{Method} & \textbf{Train Error} & \textbf{Dev Error} & \textbf{Test Error} & \textbf{All-zero-error}\tabularnewline
\hline
%\midrule
Net (A) & 0.4011 &  0.4213 & \textbf{0.4209} & 0.5166\tabularnewline
\hline
Net (B) & 0.4122 & 0.4251 & 0.4247 & 0.5166\tabularnewline
\hline
%\bottomrule
\end{tabular}
\caption{RMSLE of deep networks built on top of mean word vectors}
\end{table}

\end{textblock}

\begin{textblock}{7.0}(16,1.5)

\medskip
\hrule\medskip
\Head{Recurrent Net Results}\\

Training with LSTMs and GRUs is delicate since convergence is not assured, and parameters such as the optimizer are critical. However, we have found an architecture which yields good results, combining a recurrent LSTM/GRU with a layer of 128 hidden units with \emph{ReLU} activation. Although LSTMs and GRUs have proved to be very similar in performance, we have noticed a slight general improvement with GRUs, and so we will report those results. We have mainly used the \emph{adam} optimizer, showing very good results compared to \emph{adagrad}, \emph{RMSProp} or \emph{sgd}, which had slower convergence or non-convergence at all.

\begin{table}[h]
\centering
\vspace{2ex}
\begin{tabular}{l l l l l l}
% \toprule
\textbf{Epochs} & \textbf{Dropout} & \textbf{Batch size} & \textbf{Optimizer} & \textbf{Test Error} & \textbf{All-zero-error}\tabularnewline
\hline
%\midrule
5 & 0.1 & 16 & SGD & 0.4545 & 0.5132\tabularnewline
\hline
5 & 0.1 & 32 & adam & 0.4352 & 0.5132\tabularnewline
\hline
15 & 0.1 & 64 & adam & 0.4293 & 0.5132\tabularnewline
\hline
30 & 0.1 & 32 & adam & \textbf{0.4278} & 0.5132\tabularnewline
\hline
50 & 0.1 & 32 & adam & 0.4319 & 0.5132\tabularnewline
\hline
50 & 0.5 & 32 & adam & 0.4327 & 0.5132\tabularnewline
\hline
%\bottomrule
\end{tabular}
\caption{RMSLE of Gated Recurrent Units (GRU)}
\end{table}

\medskip
\hrule\medskip
\Head{Convolutional Net Results}\\

Finally, we utilized Convolutional Neural Networks as feature detectors on sentence ``images''. We utilize a model similar to [Kim 2014], and build $n$-gram convolutional feature detectors of sizes 3, 4, 5 and 6, ensuring we have 5 of each. We define a maximum Yelp review length (in words) of 250, and use word vectors of size 200. We tried fixed and floating word vectors, as well as a random initiation. We used batches of size 150, and trained for 20 epochs using Adadelta.

\begin{table}[h]
\centering
\vspace{2ex}
\begin{tabular}{l l l l l}
% \toprule
\textbf{Method} & \textbf{Train Error} & \textbf{Dev Error} & \textbf{Test Error} & \textbf{All-zero-error}\tabularnewline
\hline
%\midrule
Conv, WV fixed & 0.4191 &  0.4432 & 0.4306 & 0.5201\tabularnewline
\hline
Conv, WV optimized & 0.3701 & 0.4002 & \textbf{0.4015} & 0.5201\tabularnewline
\hline
Conv, random WV & 0.3814 & 0.4154 & 0.4139 & 0.5201\tabularnewline
\hline
%\bottomrule
\end{tabular}
\caption{RMSLE of convolutional networks}
\end{table}

\medskip
\hrule\medskip
\Head{Conclusion}\\
Using the metric outlined in the Yelp Kaggle competition, we examined the effectiveness of deep learning on tackling humor detection in Yelp reviews. As we would expect, basic ``shallow'' algorithms do not perform particularly well.

\end{textblock}

\end{document}
